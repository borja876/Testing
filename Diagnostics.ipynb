{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, KFold, cross_val_predict\n",
    "from sklearn.decomposition import PCA as sklearn_pca\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import preprocessing, decomposition\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.linear_model.stochastic_gradient import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "      ...       texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0     ...               17.33           184.60      2019.0            0.1622   \n",
       "1     ...               23.41           158.80      1956.0            0.1238   \n",
       "2     ...               25.53           152.50      1709.0            0.1444   \n",
       "3     ...               26.50            98.87       567.7            0.2098   \n",
       "4     ...               16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read and import data\n",
    "data = pd.read_csv('breastcancerdata.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the columns in the raw data\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      "id                         569 non-null int64\n",
      "diagnosis                  569 non-null object\n",
      "radius_mean                569 non-null float64\n",
      "texture_mean               569 non-null float64\n",
      "perimeter_mean             569 non-null float64\n",
      "area_mean                  569 non-null float64\n",
      "smoothness_mean            569 non-null float64\n",
      "compactness_mean           569 non-null float64\n",
      "concavity_mean             569 non-null float64\n",
      "concave points_mean        569 non-null float64\n",
      "symmetry_mean              569 non-null float64\n",
      "fractal_dimension_mean     569 non-null float64\n",
      "radius_se                  569 non-null float64\n",
      "texture_se                 569 non-null float64\n",
      "perimeter_se               569 non-null float64\n",
      "area_se                    569 non-null float64\n",
      "smoothness_se              569 non-null float64\n",
      "compactness_se             569 non-null float64\n",
      "concavity_se               569 non-null float64\n",
      "concave points_se          569 non-null float64\n",
      "symmetry_se                569 non-null float64\n",
      "fractal_dimension_se       569 non-null float64\n",
      "radius_worst               569 non-null float64\n",
      "texture_worst              569 non-null float64\n",
      "perimeter_worst            569 non-null float64\n",
      "area_worst                 569 non-null float64\n",
      "smoothness_worst           569 non-null float64\n",
      "compactness_worst          569 non-null float64\n",
      "concavity_worst            569 non-null float64\n",
      "concave points_worst       569 non-null float64\n",
      "symmetry_worst             569 non-null float64\n",
      "fractal_dimension_worst    569 non-null float64\n",
      "Unnamed: 32                0 non-null float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#Check the kind of variables in the raw data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#deleting the \"id\" column\n",
    "data.drop(\"id\",axis=1,inplace=True)\n",
    "#deleting the \"Unnamed: 32\" column\n",
    "data.drop(\"Unnamed: 32\",axis=1,inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      "diagnosis                  569 non-null object\n",
      "radius_mean                569 non-null float64\n",
      "texture_mean               569 non-null float64\n",
      "perimeter_mean             569 non-null float64\n",
      "area_mean                  569 non-null float64\n",
      "smoothness_mean            569 non-null float64\n",
      "compactness_mean           569 non-null float64\n",
      "concavity_mean             569 non-null float64\n",
      "concave points_mean        569 non-null float64\n",
      "symmetry_mean              569 non-null float64\n",
      "fractal_dimension_mean     569 non-null float64\n",
      "radius_se                  569 non-null float64\n",
      "texture_se                 569 non-null float64\n",
      "perimeter_se               569 non-null float64\n",
      "area_se                    569 non-null float64\n",
      "smoothness_se              569 non-null float64\n",
      "compactness_se             569 non-null float64\n",
      "concavity_se               569 non-null float64\n",
      "concave points_se          569 non-null float64\n",
      "symmetry_se                569 non-null float64\n",
      "fractal_dimension_se       569 non-null float64\n",
      "radius_worst               569 non-null float64\n",
      "texture_worst              569 non-null float64\n",
      "perimeter_worst            569 non-null float64\n",
      "area_worst                 569 non-null float64\n",
      "smoothness_worst           569 non-null float64\n",
      "compactness_worst          569 non-null float64\n",
      "concavity_worst            569 non-null float64\n",
      "concave points_worst       569 non-null float64\n",
      "symmetry_worst             569 non-null float64\n",
      "fractal_dimension_worst    569 non-null float64\n",
      "dtypes: float64(30), object(1)\n",
      "memory usage: 137.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#Check variables type after deleting the ones we are not using\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting the diagnosis variable\n",
    "data.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Diagclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean    ...      texture_worst  perimeter_worst  area_worst  \\\n",
       "0         0.2419    ...              17.33           184.60      2019.0   \n",
       "1         0.1812    ...              23.41           158.80      1956.0   \n",
       "2         0.2069    ...              25.53           152.50      1709.0   \n",
       "3         0.2597    ...              26.50            98.87       567.7   \n",
       "4         0.1809    ...              16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  Diagclass  \n",
       "0          0.4601                  0.11890        1.0  \n",
       "1          0.2750                  0.08902        1.0  \n",
       "2          0.3613                  0.08758        1.0  \n",
       "3          0.6638                  0.17300        1.0  \n",
       "4          0.2364                  0.07678        1.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform classifying variable into numeric variable [0,1] and add a column\n",
    "data.loc[data['diagnosis'] == 'M', 'Diagclass'] = 1\n",
    "data.loc[data['diagnosis'] == 'B', 'Diagclass'] = 0\n",
    "\n",
    "#Check dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dataset with new classifying variable \"Diagclass\" and withouth the diagnosis column\n",
    "data.drop(\"diagnosis\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    357\n",
       "1.0    212\n",
       "Name: Diagclass, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting the diagnosis variable\n",
    "data.Diagclass.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    212\n",
       "0.0    212\n",
       "Name: Diagclass, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#UPsample the minority class \n",
    "\n",
    "# Separate majority and minority classes\n",
    "Diagclass_majority = data[data.Diagclass==0]\n",
    "Diagclass_minority = data[data.Diagclass==1]\n",
    " \n",
    "# Downsample Diaclass majority\n",
    "Diagclass_majority_downsampled = resample(Diagclass_majority, replace=False, n_samples=212, random_state=123) \n",
    " \n",
    "# Combine majority class with downsampled najority class\n",
    "data1 = pd.concat([Diagclass_majority_downsampled, Diagclass_minority])\n",
    " \n",
    "# Display new class counts\n",
    "data1.Diagclass.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define predictors and predicted variables\n",
    "\n",
    "X = data1.drop('Diagclass', axis = 1)\n",
    "Y = data1['Diagclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.956598</td>\n",
       "      <td>-0.958038</td>\n",
       "      <td>-0.913282</td>\n",
       "      <td>-0.872491</td>\n",
       "      <td>-0.969602</td>\n",
       "      <td>-0.000376</td>\n",
       "      <td>-0.006668</td>\n",
       "      <td>-0.697853</td>\n",
       "      <td>-0.088861</td>\n",
       "      <td>1.356285</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.024784</td>\n",
       "      <td>-1.188043</td>\n",
       "      <td>-0.967787</td>\n",
       "      <td>-0.882992</td>\n",
       "      <td>-1.047159</td>\n",
       "      <td>0.046622</td>\n",
       "      <td>0.012035</td>\n",
       "      <td>-0.645890</td>\n",
       "      <td>-1.247672</td>\n",
       "      <td>1.032811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.583078</td>\n",
       "      <td>-0.897986</td>\n",
       "      <td>-1.485759</td>\n",
       "      <td>-1.261459</td>\n",
       "      <td>-0.202170</td>\n",
       "      <td>0.228499</td>\n",
       "      <td>-0.101747</td>\n",
       "      <td>-0.806465</td>\n",
       "      <td>-1.886917</td>\n",
       "      <td>1.234636</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.539214</td>\n",
       "      <td>-1.487627</td>\n",
       "      <td>-1.428643</td>\n",
       "      <td>-1.176236</td>\n",
       "      <td>-0.721886</td>\n",
       "      <td>-0.513025</td>\n",
       "      <td>-0.682571</td>\n",
       "      <td>-1.291279</td>\n",
       "      <td>-2.019485</td>\n",
       "      <td>-0.409368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0    -0.956598     -0.958038       -0.913282  -0.872491        -0.969602   \n",
       "1    -1.583078     -0.897986       -1.485759  -1.261459        -0.202170   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0         -0.000376       -0.006668            -0.697853      -0.088861   \n",
       "1          0.228499       -0.101747            -0.806465      -1.886917   \n",
       "\n",
       "   fractal_dimension_mean           ...             radius_worst  \\\n",
       "0                1.356285           ...                -1.024784   \n",
       "1                1.234636           ...                -1.539214   \n",
       "\n",
       "   texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0      -1.188043        -0.967787   -0.882992         -1.047159   \n",
       "1      -1.487627        -1.428643   -1.176236         -0.721886   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0           0.046622         0.012035             -0.645890       -1.247672   \n",
       "1          -0.513025        -0.682571             -1.291279       -2.019485   \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0                 1.032811  \n",
       "1                -0.409368  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocess and scale data\n",
    "names = X.columns\n",
    "X1 = pd.DataFrame(preprocessing.scale(X), columns = names)\n",
    "X1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***PCA Analysis***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFxGJif8PLSqNs7uOcB8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18bcd7a6b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of total variance in the dataset explained by each component from Sklearn PCA.\n",
      " [  6.14751572e-01   2.06951967e-01   9.27501027e-02   3.87369266e-02\n",
      "   2.01461419e-02   1.16794352e-02   5.99447302e-03   2.83201672e-03\n",
      "   1.98332083e-03   1.37275536e-03   9.57200397e-04   8.51675019e-04\n",
      "   3.88770210e-04   2.98866290e-04   1.08971366e-04   5.21596739e-05\n",
      "   4.29142907e-05   3.18389467e-05   2.26298702e-05   1.45550946e-05\n",
      "   1.16946836e-05   1.00308463e-05   3.98949098e-06   3.47502492e-06\n",
      "   1.67783563e-06   7.79036138e-07   4.58220614e-08   1.19299345e-08\n",
      "   2.68822775e-09   1.38496983e-32]\n"
     ]
    }
   ],
   "source": [
    "# Build up the correlation mtrix\n",
    "Z = X1\n",
    "correlation_matrix = Z.corr()\n",
    "\n",
    "#Eigenvectores & Eigenvalues\n",
    "\n",
    "eig_vals, eig_vecs = np.linalg.eig(correlation_matrix)\n",
    "\n",
    "sklearn_pca = PCA(n_components=len(Z.columns))\n",
    "Y_sklearn = sklearn_pca.fit_transform(correlation_matrix)\n",
    "\n",
    "#From the Scree plot.\n",
    "\n",
    "plt.plot(eig_vals)\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    'The percentage of total variance in the dataset explained by each',\n",
    "    'component from Sklearn PCA.\\n',\n",
    "    sklearn_pca.explained_variance_ratio_\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.003006</td>\n",
       "      <td>3.481583</td>\n",
       "      <td>2.415757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.537136</td>\n",
       "      <td>3.404853</td>\n",
       "      <td>3.962812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.211706</td>\n",
       "      <td>-1.580275</td>\n",
       "      <td>1.245082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.484037</td>\n",
       "      <td>1.242662</td>\n",
       "      <td>0.422837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.740544</td>\n",
       "      <td>0.808732</td>\n",
       "      <td>-1.005692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0 -1.003006  3.481583  2.415757\n",
       "1 -2.537136  3.404853  3.962812\n",
       "2 -4.211706 -1.580275  1.245082\n",
       "3 -4.484037  1.242662  0.422837\n",
       "4 -2.740544  0.808732 -1.005692"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PCA features\n",
    "\n",
    "# Create a scaler object\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features and transform\n",
    "X_std = sc.fit_transform(X1)\n",
    "\n",
    "# Create a PCA object from Scree plot the number of components is 3\n",
    "pca = decomposition.PCA(n_components=3)\n",
    "\n",
    "# Fit the PCA and transform the data\n",
    "X_std_pca = pca.fit_transform(X_std)\n",
    "\n",
    "# View the new feature data's shape\n",
    "X_std_pca.shape\n",
    "\n",
    "# Create a new dataframe with the new features\n",
    "\n",
    "XPCA = pd.DataFrame(X_std_pca)\n",
    "XPCA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAacCAYAAACxKIzzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nU/EkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18bcd7a66a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Calculate Feature Importance using Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X1, Y)\n",
    "\n",
    "#Define feature importance\n",
    "feature_importance = rf.feature_importances_\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.figure(figsize=(7, 30))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X1.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Diagclass')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>concave points_worst</th>\n",
       "      <td>778.324989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_worst</th>\n",
       "      <td>597.008511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_mean</th>\n",
       "      <td>590.535896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_worst</th>\n",
       "      <td>565.973575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_mean</th>\n",
       "      <td>477.235649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_mean</th>\n",
       "      <td>443.106946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_worst</th>\n",
       "      <td>430.025210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_mean</th>\n",
       "      <td>408.012843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_worst</th>\n",
       "      <td>407.719036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_mean</th>\n",
       "      <td>365.352404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_worst</th>\n",
       "      <td>252.482255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_mean</th>\n",
       "      <td>236.259236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_se</th>\n",
       "      <td>171.794912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_se</th>\n",
       "      <td>168.054543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_se</th>\n",
       "      <td>147.142357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_worst</th>\n",
       "      <td>129.903503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>108.358176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_se</th>\n",
       "      <td>104.620728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_worst</th>\n",
       "      <td>88.502493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_worst</th>\n",
       "      <td>80.090072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_mean</th>\n",
       "      <td>69.902966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <td>59.963815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_mean</th>\n",
       "      <td>53.402272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_se</th>\n",
       "      <td>50.956538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_se</th>\n",
       "      <td>47.103824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <td>3.290638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_se</th>\n",
       "      <td>2.555672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_se</th>\n",
       "      <td>0.111030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <td>0.054190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_se</th>\n",
       "      <td>0.025794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Best Features\n",
       "concave points_worst        778.324989\n",
       "perimeter_worst             597.008511\n",
       "concave points_mean         590.535896\n",
       "radius_worst                565.973575\n",
       "perimeter_mean              477.235649\n",
       "radius_mean                 443.106946\n",
       "concavity_worst             430.025210\n",
       "concavity_mean              408.012843\n",
       "area_worst                  407.719036\n",
       "area_mean                   365.352404\n",
       "compactness_worst           252.482255\n",
       "compactness_mean            236.259236\n",
       "radius_se                   171.794912\n",
       "perimeter_se                168.054543\n",
       "area_se                     147.142357\n",
       "texture_worst               129.903503\n",
       "texture_mean                108.358176\n",
       "concave points_se           104.620728\n",
       "smoothness_worst             88.502493\n",
       "symmetry_worst               80.090072\n",
       "smoothness_mean              69.902966\n",
       "fractal_dimension_worst      59.963815\n",
       "symmetry_mean                53.402272\n",
       "compactness_se               50.956538\n",
       "concavity_se                 47.103824\n",
       "fractal_dimension_se          3.290638\n",
       "smoothness_se                 2.555672\n",
       "symmetry_se                   0.111030\n",
       "fractal_dimension_mean        0.054190\n",
       "texture_se                    0.025794"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Selection. Scores for the most relevant features (should we start with the one that has more explanatory power)\n",
    "\n",
    "# feature extraction\n",
    "test = SelectKBest()\n",
    "fit = test.fit(X1, Y)\n",
    "\n",
    "#Identify features with highest score from a predictive perspective (for all programs)\n",
    "names2 = X1.columns\n",
    "Bestfeatures = pd.DataFrame(fit.scores_, index = names2)\n",
    "Bestfeatures.columns = ['Best Features']\n",
    "Bestfeatures.sort_values(by=['Best Features'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>perimeter_worst</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>radius_worst</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>concave points_worst</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>radius_se</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>texture_worst</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>area_worst</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>smoothness_worst</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radius_mean</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>concavity_worst</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>area_se</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fractal_dimension_se</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>concavity_mean</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>perimeter_se</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>concave points_mean</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>compactness_mean</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perimeter_mean</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>texture_mean</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>symmetry_worst</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>symmetry_se</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area_mean</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>concave points_se</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>compactness_se</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>fractal_dimension_worst</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fractal_dimension_mean</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>symmetry_mean</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>compactness_worst</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>smoothness_se</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>concavity_se</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smoothness_mean</td>\n",
       "      <td>27</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>texture_se</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Features  Ranking  Support\n",
       "22          perimeter_worst        1     True\n",
       "20             radius_worst        1     True\n",
       "27     concave points_worst        1     True\n",
       "10                radius_se        2    False\n",
       "21            texture_worst        3    False\n",
       "23               area_worst        4    False\n",
       "24         smoothness_worst        5    False\n",
       "0               radius_mean        6    False\n",
       "26          concavity_worst        7    False\n",
       "13                  area_se        8    False\n",
       "19     fractal_dimension_se        9    False\n",
       "6            concavity_mean       10    False\n",
       "12             perimeter_se       11    False\n",
       "7       concave points_mean       12    False\n",
       "5          compactness_mean       13    False\n",
       "2            perimeter_mean       14    False\n",
       "1              texture_mean       15    False\n",
       "28           symmetry_worst       16    False\n",
       "18              symmetry_se       17    False\n",
       "3                 area_mean       18    False\n",
       "17        concave points_se       19    False\n",
       "15           compactness_se       20    False\n",
       "29  fractal_dimension_worst       21    False\n",
       "9    fractal_dimension_mean       22    False\n",
       "8             symmetry_mean       23    False\n",
       "25        compactness_worst       24    False\n",
       "14            smoothness_se       25    False\n",
       "16             concavity_se       26    False\n",
       "4           smoothness_mean       27    False\n",
       "11               texture_se       28    False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the RFE model and select features\n",
    "\n",
    "#From PCA analyis the number of components is 3\n",
    "\n",
    "nfeatures = 3\n",
    "lr = LogisticRegression()\n",
    "rfe = RFE(lr,nfeatures)\n",
    "fit = rfe.fit(X1,Y)\n",
    "\n",
    "# summarize the selection of the features\n",
    "\n",
    "result_RFE = pd.DataFrame(list(zip(X1.head(0), rfe.ranking_, rfe.support_)),columns=['Features','Ranking','Support'] )\n",
    "result_RFE.sort_values('Ranking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Feature Selection***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
       "       'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View all the predictors to make the feature selection\n",
    "X1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature Selection using Random Forest\n",
    "X3 = X1[['perimeter_worst', 'area_worst', 'concave points_mean', 'concavity_mean','radius_worst','perimeter_mean',\n",
    "'concavity_worst', 'compactness_mean','concave points_worst','compactness_worst']]\n",
    "\n",
    "#Feature Selection using RFE & PCA\n",
    "X2 = X1[['radius_worst','concave points_worst','perimeter_worst']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split the data into training and testing datasets. Split: 70/30; train/test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2,Y, test_size=0.3, random_state=123)\n",
    "\n",
    "#Initiating the cross validation generator, N splits = 5\n",
    "\n",
    "kf = KFold(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Logistic Regression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "#Tune parameters\n",
    "\n",
    "k1 = np.arange(20)+1\n",
    "k2 = ['l1','l2']\n",
    "\n",
    "parameters = {'C': k1,\n",
    "             'penalty':k2\n",
    "             }\n",
    "\n",
    "#Fit parameters\n",
    "\n",
    "lr1 = GridSearchCV(lr, param_grid=parameters, cv=kf)\n",
    "\n",
    "#Fit the tunned classifier in the traiing space\n",
    "lr1.fit(X_train, y_train)\n",
    "\n",
    "#Print the best parameters\n",
    "print(lr1.best_params_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA accuracy: 0.9387114845938374\n",
      "RFE accuracy: 0.9268627450980393\n",
      "FI accuracy: 0.9245658263305323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Have a raw idea of the accuracy of each of the feeatures selection carried out with different methodologies\n",
    "lr1.fit(XPCA, Y)\n",
    "\n",
    "# Predict on test set\n",
    "predPCA_y = lr1.predict(XPCA)\n",
    "\n",
    "print((\n",
    "    'PCA accuracy: {}\\n'\n",
    "    'RFE accuracy: {}\\n'\n",
    "    'FI accuracy: {}\\n'\n",
    ").format(cross_val_score(lr1,XPCA,Y,cv=kf).mean(),cross_val_score(lr,X2,Y,cv=kf).mean(),cross_val_score(lr,X3,Y,cv=kf).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit on Test set\n",
    "lr1.fit(X_test, y_test)\n",
    "\n",
    "predtest_y = lr1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.97      0.95        64\n",
      "        1.0       0.97      0.94      0.95        64\n",
      "\n",
      "avg / total       0.95      0.95      0.95       128\n",
      "\n",
      "[[62  2]\n",
      " [ 4 60]]\n",
      "Logistic Regression accuracy: 0.9452307692307691\n",
      "Logistic Regression accuracy PCA: 0.9387114845938374\n",
      "Percent Type I errors: 0.015625\n",
      "Percent Type II errors: 0.03125\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate model (test set)\n",
    "target_names = ['0.0', '1.0']\n",
    "print(classification_report(y_test, predtest_y, target_names=target_names))\n",
    "\n",
    "confusion = confusion_matrix(y_test, predtest_y)\n",
    "print(confusion)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_test = pd.crosstab(y_test, predtest_y, margins=True)\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0] / table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0] / table_test.loc['All','All']\n",
    "\n",
    "\n",
    "acclr1 = cross_val_score(lr1,X_test,y_test,cv=kf).mean()\n",
    "acclr1pca = cross_val_score(lr1,XPCA,Y,cv=kf).mean()\n",
    "\n",
    "print((\n",
    "    'Logistic Regression accuracy: {}\\n'\n",
    "    'Logistic Regression accuracy PCA: {}\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    ").format(acclr1,acclr1pca,test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Naive Bayes***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1}\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "\n",
    "lb = BernoulliNB()\n",
    "\n",
    "#Tune parameters\n",
    "\n",
    "k1 = np.arange(10)+1\n",
    "\n",
    "parameters = {'alpha': k1}\n",
    "\n",
    "#Fit parameters\n",
    "\n",
    "lb1 = GridSearchCV(lb, param_grid=parameters, cv=kf)\n",
    "\n",
    "#Fit the tunned classifier in the traiing space\n",
    "lb1.fit(X_train, y_train)\n",
    "\n",
    "#Print the best parameters\n",
    "print(lb1.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict on the test data set\n",
    "\n",
    "lb1.fit(X_test, y_test)\n",
    "\n",
    "# Predict on training set\n",
    "predtestlb_y = lb1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.98      0.91        64\n",
      "        1.0       0.98      0.83      0.90        64\n",
      "\n",
      "avg / total       0.92      0.91      0.91       128\n",
      "\n",
      "[[63  1]\n",
      " [11 53]]\n",
      "Naive Bayes accuracy: 0.9064615384615384\n",
      "Naive Bayes accuracy PCA: 0.9031932773109244\n",
      "Percent Type I errors: 0.0078125\n",
      "Percent Type II errors: 0.0859375\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of the model (testing)\n",
    "\n",
    "target_names = ['0.0', '1.0']\n",
    "print(classification_report(y_test, predtestlb_y, target_names=target_names))\n",
    "\n",
    "confusion = confusion_matrix(y_test, predtestlb_y)\n",
    "print(confusion)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_test = pd.crosstab(y_test, predtestlb_y, margins=True)\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0] / table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0] / table_test.loc['All','All']\n",
    "\n",
    "acclb1 = cross_val_score(lb1,X_test,y_test,cv=kf).mean()\n",
    "acclb1pca = cross_val_score(lb1,XPCA, Y,cv=kf).mean()\n",
    "\n",
    "print((\n",
    "    'Naive Bayes accuracy: {}\\n'\n",
    "    'Naive Bayes accuracy PCA: {}\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    ").format(acclb1,acclb1pca,test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***KNN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'weights': 'uniform', 'n_neighbors': 15, 'algorithm': 'auto', 'leaf_size': 40}\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model\n",
    "KNN = KNeighborsClassifier(n_jobs=-1)\n",
    "\n",
    "#Create range of values to fit parameters\n",
    "\n",
    "k1 = [11,13,15,17,19,21]\n",
    "k2 = [40,50,60]\n",
    "k3 = ['uniform', 'distance']\n",
    "k4 = ['auto', 'ball_tree','kd_tree','brute']\n",
    "\n",
    "parameters = {'n_neighbors': k1,\n",
    "          'leaf_size': k2,\n",
    "          'weights':k3,\n",
    "          'algorithm':k4}\n",
    "\n",
    "#Fit parameters\n",
    "\n",
    "clf = GridSearchCV(KNN, param_grid=parameters, cv=kf)\n",
    "\n",
    "#Fit the tunned model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize the model on test dataset\n",
    "\n",
    "clf.fit(X_test, y_test)\n",
    "\n",
    "# Predict on test dataset\n",
    "\n",
    "predtest3_y = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.95      0.95        64\n",
      "        1.0       0.95      0.94      0.94        64\n",
      "\n",
      "avg / total       0.95      0.95      0.95       128\n",
      "\n",
      "[[61  3]\n",
      " [ 4 60]]\n",
      "KNN accuracy: 0.9375384615384614\n",
      "KNN accuracy PCA: 0.917422969187675\n",
      "Percent Type I errors: 0.0234375\n",
      "Percent Type II errors: 0.03125\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate model on the test set\n",
    "target_names = ['0.0', '1.0']\n",
    "print(classification_report(y_test, predtest3_y, target_names=target_names))\n",
    "\n",
    "#Create confusion matrix\n",
    "confusion = confusion_matrix(y_test, predtest3_y)\n",
    "print(confusion)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_test = pd.crosstab(y_test, predtest3_y, margins=True)\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0] / table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0] / table_test.loc['All','All']\n",
    "\n",
    "accclf = cross_val_score(clf,X_test,y_test,cv=kf).mean()\n",
    "accclfpca = cross_val_score(clf,XPCA,Y,cv=kf).mean()\n",
    "\n",
    "#Print Results\n",
    "print((\n",
    "    'KNN accuracy: {}\\n'\n",
    "    'KNN accuracy PCA: {}\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    ").format(accclf,accclfpca,test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Random Forest***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs = -1)\n",
    "\n",
    "#Create range of values to fit parameters\n",
    "\n",
    "k1 = [20,100,300]\n",
    "\n",
    "parameters = {'n_estimators':k1}\n",
    "\n",
    "#Fit parameters\n",
    "\n",
    "rf1 = GridSearchCV(rf, param_grid=parameters, cv=kf)\n",
    "\n",
    "#Fit the tunned model\n",
    "rf1.fit(X_train, y_train)\n",
    "\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\", rf1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit in test dataset\n",
    "rf1.fit(X_test, y_test)\n",
    "\n",
    "#Predict on test dataset\n",
    "predtestrf_y = rf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99        64\n",
      "          1       1.00      0.98      0.99        64\n",
      "\n",
      "avg / total       0.99      0.99      0.99       128\n",
      "\n",
      "[[64  0]\n",
      " [ 1 63]]\n",
      "Random Forest accuracy:0.9295384615384616\n",
      "Random Forest accuracy PCA:0.9340056022408962\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0078125\n"
     ]
    }
   ],
   "source": [
    "#Test Scores\n",
    "target_names = ['0', '1']\n",
    "print(classification_report(y_test, predtestrf_y, target_names=target_names))\n",
    "cnf = confusion_matrix(y_test, predtestrf_y)\n",
    "print(cnf)\n",
    "\n",
    "table_test = pd.crosstab(y_test, predtestrf_y, margins=True)\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "accrf1 = cross_val_score(rf1,X_test,y_test,cv=kf).mean()\n",
    "accrf1pca = cross_val_score(rf1,XPCA,Y,cv=kf).mean()\n",
    "\n",
    "print((\n",
    "    'Random Forest accuracy:{}\\n'\n",
    "    'Random Forest accuracy PCA:{}\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(accrf1,accrf1pca,test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Decision Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'max_features': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "OTM = DecisionTreeClassifier()\n",
    "\n",
    "#Create range of values to fit parameters\n",
    "\n",
    "\n",
    "k1 = ['auto', 'sqrt', 'log2']\n",
    "\n",
    "\n",
    "parameters = {'max_features': k1\n",
    "         }\n",
    "\n",
    "#Fit parameters\n",
    "\n",
    "OTM1 = GridSearchCV(OTM, param_grid=parameters, cv=kf)\n",
    "\n",
    "#Fit the tunned model\n",
    "OTM1.fit(X_train, y_train)\n",
    "\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\", OTM1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit on test dataset\n",
    "OTM1.fit(X_test, y_test)\n",
    "\n",
    "#Predict parameters on test dataset\n",
    "\n",
    "predtestrf1_y = OTM1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        64\n",
      "          1       1.00      1.00      1.00        64\n",
      "\n",
      "avg / total       1.00      1.00      1.00       128\n",
      "\n",
      "[[64  0]\n",
      " [ 0 64]]\n",
      "Decision Tree accuracy:0.8898461538461537\n",
      "Decision Tree accuracy PCA:0.8844257703081233\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Test Scores\n",
    "target_names = ['0', '1']\n",
    "print(classification_report(y_test, predtestrf1_y, target_names=target_names))\n",
    "cnf = confusion_matrix(y_test, predtestrf1_y)\n",
    "print(cnf)\n",
    "\n",
    "table_test = pd.crosstab(y_test, predtestrf1_y, margins=True)\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "OTM1acc = cross_val_score(OTM1,X_test,y_test,cv=kf).mean()\n",
    "OTM1accpca = cross_val_score(OTM1,XPCA,Y,cv=kf).mean()\n",
    "\n",
    "print((\n",
    "    'Decision Tree accuracy:{}\\n'\n",
    "    'Decision Tree accuracy PCA:{}\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(OTM1acc,OTM1accpca, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SVC***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'kernel': 'linear', 'C': 3}\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "svc = SVC()\n",
    "\n",
    "#Create range of values to fit parameters\n",
    "k1 = np.arange(20)+1\n",
    "k2 =  ['linear','rbf']\n",
    "\n",
    "\n",
    "parameters = {'C': k1, \n",
    "          'kernel': k2}\n",
    "\n",
    "#Fit parameters\n",
    "\n",
    "svc1 = GridSearchCV(svc, param_grid=parameters, cv=kf)\n",
    "\n",
    "#Fit the tunned model\n",
    "svc1.fit(X_train, y_train)\n",
    "\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\", svc1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit tunned model on Test set\n",
    "svc1.fit(X_test, y_test)\n",
    "\n",
    "# Predict on training set\n",
    "predtestsvc_y = svc1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.95      0.95        64\n",
      "        1.0       0.95      0.94      0.94        64\n",
      "\n",
      "avg / total       0.95      0.95      0.95       128\n",
      "\n",
      "[[61  3]\n",
      " [ 4 60]]\n",
      "SVC accuracy:0.9375384615384617\n",
      "SVC accuracy PCA:0.9127450980392157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test Scores\n",
    "target_names = ['0.0', '1.0']\n",
    "print(classification_report(y_test, predtestsvc_y, target_names=target_names))\n",
    "cnf = confusion_matrix(y_test, predtestsvc_y)\n",
    "print(cnf)\n",
    "\n",
    "table_test = pd.crosstab(y_test, predtestsvc_y, margins=True)\n",
    "\n",
    "accsvc1 = cross_val_score(svc1,X_test,y_test,cv=kf).mean()\n",
    "accsvc1pca = cross_val_score(svc1,XPCA,Y,cv=kf).mean()\n",
    "\n",
    "print((\n",
    "    'SVC accuracy:{}\\n'\n",
    "    'SVC accuracy PCA:{}\\n'\n",
    ").format(accsvc1,accsvc1pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Gradient Boosting***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'criterion': 'mae', 'loss': 'deviance', 'n_estimators': 88}\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "GBC = GradientBoostingClassifier()\n",
    "\n",
    "k1 = ['deviance','exponential']\n",
    "k2 = np.arange(100)+1\n",
    "k5 = ['friedman_mse','mse','mae']\n",
    "\n",
    "parameters = {'loss': k1,\n",
    "             'n_estimators': k2,\n",
    "             'criterion': k5}\n",
    "\n",
    "#Fit parameters\n",
    "\n",
    "GBC1 = GridSearchCV(GBC, param_grid=parameters, cv=kf)\n",
    "\n",
    "#Fit the tunned model\n",
    "GBC1.fit(X_train, y_train)\n",
    "\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\", GBC1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit on the test set\n",
    "GBC1.fit(X_test, y_test)\n",
    "\n",
    "# Predict on test set\n",
    "\n",
    "predtestgb_y = GBC1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        64\n",
      "          1       1.00      1.00      1.00        64\n",
      "\n",
      "avg / total       1.00      1.00      1.00       128\n",
      "\n",
      "[[64  0]\n",
      " [ 0 64]]\n",
      "Gradient Boosting accuracy:0.9052307692307693\n",
      "Gradient Boosting accuracy PCA:0.9175350140056023\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Test Scores\n",
    "target_names = ['0', '1']\n",
    "print(classification_report(y_test, predtestgb_y, target_names=target_names))\n",
    "cnf = confusion_matrix(y_test, predtestgb_y)\n",
    "print(cnf)\n",
    "\n",
    "table_test = pd.crosstab(y_test, predtestgb_y, margins=True)\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "accGBC1 = cross_val_score(GBC1,X_test,y_test,cv=kf).mean()\n",
    "accGBC1pca = cross_val_score(GBC1,XPCA,Y,cv=kf).mean()\n",
    "\n",
    "print((\n",
    "    'Gradient Boosting accuracy:{}\\n'\n",
    "    'Gradient Boosting accuracy PCA:{}\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(accGBC1,accGBC1pca,test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Conclusion***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the breast Cancer Diagnostic dataset with 569 entries a model has been built to predict based on the most relevant features obtained if a tumor is benign or malign. In this case we have used classifiers to build the models and the hyperparameters have been tuned on the training set, accounting for 70% of all the data and test on the remaining 30%. As a result, all the models tested have an accuracy that goes from 89% in the worst-case scenario up to 95% in the best case. The models used have been logistic regression, KNN, SVC, Random Forest, Naïve Bayes (Bernouilli, Gradient Boosting and Decision Tree). All hyperparameters of the models and the models have been tested using cross validation with five folds.\n",
    "The first step has been to create and select the features that will be the predictors of the model and to build the output variable as a [0,1] variable. In the latter, the dataset has been resampled to balance the number of outputs in each class. For the feature selection, Random forest best features, select best and recursive feature elimination have been used. Additionally is has been compared to the number of features that a PCA analysis gives as meaningful for the model. In the case of the feature selection models used, the features selected using random forest have been narrowed down to the ones produced by the recursive feature elimination using as the maximum number of features the number given by the PCA analysis equating to 3.\n",
    "The selected features are: 'radius_worst','concave points_worst','perimeter_worst'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of each model: \n",
      "Logistic Regression:0.9452 \n",
      "KNN: 0.9375 \n",
      "SVC: 0.9375 \n",
      "Random Forest: 0.9295 \n",
      "Naive Bayes:0.9065 \n",
      "Gradient Boosting: 0.9052 \n",
      "Decision Tree: 0.8898 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Summary of accuracy of different models:\n",
    "\n",
    "print(('Accuracy of each model: \\n'\n",
    "     'Logistic Regression:{:.{prec}f} \\n'\n",
    "      'KNN: {:.{prec}f} \\n' \n",
    "       'SVC: {:.{prec}f} \\n'\n",
    "     'Random Forest: {:.{prec}f} \\n'\n",
    "      'Naive Bayes:{:.{prec}f} \\n' \n",
    "       'Gradient Boosting: {:.{prec}f} \\n'\n",
    "        'Decision Tree: {:.{prec}f} \\n'\n",
    "      ).format(acclr1,accclf,accsvc1,accrf1,acclb1,accGBC1,OTM1acc,prec=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
