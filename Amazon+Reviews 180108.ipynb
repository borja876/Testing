{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import cross_val_score, KFold, cross_val_predict, train_test_split,GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import json\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Import & Analize Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It's hard to believe \"Memory of Trees\" came ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>A clasically-styled and introverted album, Mem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>I never thought Enya would reach the sublime h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>This is the third review of an irish album I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Enya, despite being a successful recording art...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall                                         reviewText\n",
       "0        5  It's hard to believe \"Memory of Trees\" came ou...\n",
       "1        5  A clasically-styled and introverted album, Mem...\n",
       "2        5  I never thought Enya would reach the sublime h...\n",
       "3        5  This is the third review of an irish album I w...\n",
       "4        4  Enya, despite being a successful recording art..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import data from json file and create a list\n",
    "\n",
    "data = []\n",
    "with open('/home/borjaregueral/Digital_Music_5.json') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "#Create a dataframe with the columns that are interesting for this exercise\n",
    "#Columns left out: 'helpful', 'reviewTime', 'reviewerID','reviewerName'\n",
    "names = [\"overall\", \"reviewText\"]\n",
    "amazonraw = pd.DataFrame(data, columns=names)\n",
    "amazonraw['overall'] = amazonraw['overall'].astype(int)\n",
    "amazonraw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64706 entries, 0 to 64705\n",
      "Data columns (total 2 columns):\n",
      "overall       64706 non-null int64\n",
      "reviewText    64706 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1011.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "overall        int64\n",
       "reviewText    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analyse the dataset: types, length of the dataframe and NaN\n",
    "amazonraw.info()\n",
    "amazonraw.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Build Sentiment Scores and Categories***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    64706.000000\n",
       "mean         4.222514\n",
       "std          1.086081\n",
       "min          1.000000\n",
       "25%          4.000000\n",
       "50%          5.000000\n",
       "75%          5.000000\n",
       "max          5.000000\n",
       "Name: overall, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazonraw.overall.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change the Overall variable into a categorical variable\n",
    "#Ratings equal or lower than 3 have been considered negative as the mean is 4.25.\n",
    "#The hypothesis is that although the abovmentioned ratings could be considered positive they are negative\n",
    "\n",
    "amazonraw.loc[amazonraw['overall'] <= 3, 'Sentiment'] = 0\n",
    "amazonraw.loc[amazonraw['overall'] >=4 , 'Sentiment'] = 1\n",
    "amazonraw.loc[amazonraw['Sentiment'] == 0, 'Category'] ='Negative'\n",
    "amazonraw.loc[amazonraw['Sentiment'] == 1, 'Category'] = 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ocurrencies:\n",
      " Negative    12590\n",
      "Positive    52116\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Frequency of each value:\n",
      " Positive    0.805428\n",
      "Negative    0.194572\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Count the each of the categories\n",
    "\n",
    "a = amazonraw['Category'].value_counts('Positive')\n",
    "b = pd.value_counts(amazonraw['Category'].values, sort=False)\n",
    "\n",
    "print('Number of ocurrencies:\\n', b)\n",
    "print('\\n')\n",
    "print('Frequency of each value:\\n', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    12590\n",
       "Negative    12590\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Downsample majority class (due to computational restrictions we downsample the majority instead of upsampling the minority)\n",
    "\n",
    "# Separate majority and minority classes\n",
    "amazon_majority = amazonraw[amazonraw.Sentiment == 1]\n",
    "amazon_minority = amazonraw[amazonraw.Sentiment == 0]\n",
    " \n",
    "# Downsample mairlinesass\n",
    "amazon_majority_downsampled = resample(amazon_majority, replace=False, n_samples=12590, random_state=123) \n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "amazon = pd.concat([amazon_majority_downsampled, amazon_minority])\n",
    " \n",
    "# Display new class counts\n",
    "amazon.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Categories in the downsampled dataset')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ4AAAFNCAYAAABBgaXMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkhsegQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f647dea8208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graphical representation of the positive and negative reviews\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "ax = sns.countplot(x=\"overall\", data=amazonraw)\n",
    "plt.title('Amazon Ratings')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.set(style=\"white\")\n",
    "ax = sns.countplot(x=\"Category\", data=amazon)\n",
    "plt.title('Categories in the downsampled dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59643</th>\n",
       "      <td>5</td>\n",
       "      <td>This is a great song that will stand the test ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55386</th>\n",
       "      <td>5</td>\n",
       "      <td>I am ashamed to say that such a high rating on...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29299</th>\n",
       "      <td>4</td>\n",
       "      <td>Mobb deep have never disapointed fans , with a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61457</th>\n",
       "      <td>4</td>\n",
       "      <td>I first learned of Sharon Van Etten when Rolli...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41719</th>\n",
       "      <td>4</td>\n",
       "      <td>In a similar line as contemporary acts The Vin...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall                                         reviewText  Sentiment  \\\n",
       "59643        5  This is a great song that will stand the test ...        1.0   \n",
       "55386        5  I am ashamed to say that such a high rating on...        1.0   \n",
       "29299        4  Mobb deep have never disapointed fans , with a...        1.0   \n",
       "61457        4  I first learned of Sharon Van Etten when Rolli...        1.0   \n",
       "41719        4  In a similar line as contemporary acts The Vin...        1.0   \n",
       "\n",
       "       Category  \n",
       "59643  Positive  \n",
       "55386  Positive  \n",
       "29299  Positive  \n",
       "61457  Positive  \n",
       "41719  Positive  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create new dataframe that has the Categories, Overall scores, Sentiment and ReviewText\n",
    "names = ['Category',\"overall\",'Sentiment', \"reviewText\"]\n",
    "amazon1 = pd.DataFrame(amazon, columns=names)\n",
    "amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lines are reshuffled and 50% of the dataset is used to reduce the computing effort\n",
    "amazon2 = amazon1.sample(frac=1, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predictors and prediced variables are formed\n",
    "\n",
    "X = amazon2['reviewText']\n",
    "y = amazon2['Sentiment']\n",
    "\n",
    "#Split the data set into train and test 70/30\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X,y, test_size=0.3, random_state=135)\n",
    "\n",
    "#KFold for cross validation analysis\n",
    "kf = KFold(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Analysis starts with Bag of Words and common English words are extracted\n",
    "\n",
    "vect = CountVectorizer(analyzer = 'word', stop_words='english').fit(X_train)\n",
    "\n",
    "X_trainvec = vect.transform(X_train)\n",
    "X_testvec = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words is : 318 \n",
      "\n",
      "Examples:  ['inc', 'own', 'even', 'mine', 'hundred', 'whereupon', 'next', 'be', 'such', 'due', 'indeed', 'was', 'wherever', 'much', 'thereby', 'of', 'back', 'other', 'latterly', 'several', 'often', 'made', 'nine', 'namely', 'while', 'on', 'us', 'top', 'myself', 'do', 'less', 'everyone']\n"
     ]
    }
   ],
   "source": [
    "#Count the number of english words and take a look at the type of words that are extracted\n",
    "\n",
    "print(\"Number of stop words is :\", len(ENGLISH_STOP_WORDS), \"\\n\")\n",
    "print(\"Examples: \", list(ENGLISH_STOP_WORDS)[::10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59374\n",
      "\n",
      "\n",
      "['00', '000', '000x', '0051', '006', '007', '00am', '00s', '01', '01so', '02', '02604', '029', '03', '0304', '04', '0403', '047', '05', '054']\n",
      "\n",
      "\n",
      "['zulu', 'zumba', 'zune', 'zup', 'zutons', 'zwan', 'zwizany', 'zydeco', 'zygote', 'zz', 'zztop', 'zzz', 'zzzzzzzz', 'zzzzzzzzz', 'zzzzzzzzzz', 'zzzzzzzzzzz', 'zzzzzzzzzzzzz', 'zzzzzzzzzzzzzz', 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz', 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz']\n"
     ]
    }
   ],
   "source": [
    "#Take a look at the features identified by bag of words\n",
    "\n",
    "features_names = vect.get_feature_names()\n",
    "print(len(features_names))\n",
    "print(\"\\n\")\n",
    "# print first 20 features\n",
    "print(features_names[:20])\n",
    "print(\"\\n\")\n",
    "# print last 20 features\n",
    "print(features_names[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17626, 59374)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<17626x59374 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1288564 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Size of the X_trainvector sparse matrix\n",
    "print(X_trainvec.shape)\n",
    "X_trainvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17626,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the size of the y_train vector to avoid problems when running the logistic regression model\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Bernoulli***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize and fit the model.\n",
    "\n",
    "l3 = BernoulliNB()\n",
    "l3.fit(X_trainvec, y_train)\n",
    "\n",
    "# Predict on training set\n",
    "predtrain_y = l3.predict(X_trainvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predicting on the test set\n",
    "\n",
    "l3 = BernoulliNB()\n",
    "l3.fit(X_testvec, y_test)\n",
    "\n",
    "# Predict on training set\n",
    "predtest_y = l3.predict(X_testvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.75      0.93      0.83      3778\n",
      "        1.0       0.91      0.70      0.79      3776\n",
      "\n",
      "avg / total       0.83      0.81      0.81      7554\n",
      "\n",
      "[[3508  270]\n",
      " [1144 2632]]\n",
      "Bernouilli accuracy: 0.6943349652219266\n",
      "Percent Type I errors: 0.035742652899126294\n",
      "Percent Type II errors: 0.1514429441355573\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of the model (testing)\n",
    "\n",
    "target_names = ['0.0', '1.0']\n",
    "print(classification_report(y_test, predtest_y, target_names=target_names))\n",
    "\n",
    "confusion = confusion_matrix(y_test, predtest_y)\n",
    "print(confusion)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_test = pd.crosstab(y_test, predtest_y, margins=True)\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0] / table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0] / table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Bernouilli accuracy: {}\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    ").format(cross_val_score(l3,X_testvec,y_test,cv=kf).mean(),test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Logistic Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_trainvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Once the model has been trained test it on the test dataset\n",
    "lr.fit(X_testvec, y_test)\n",
    "\n",
    "# Predict on test set\n",
    "predtest_y = lr.predict(X_testvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.99      0.99      3778\n",
      "        1.0       0.99      0.99      0.99      3776\n",
      "\n",
      "avg / total       0.99      0.99      0.99      7554\n",
      "\n",
      "[[3745   33]\n",
      " [  31 3745]]\n",
      "Logistics accuracy: 0.74953624852626\n",
      "Percent Type I errors: 0.004368546465448769\n",
      "Percent Type II errors: 0.004103786073603389\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate model (test set)\n",
    "target_names = ['0.0', '1.0']\n",
    "print(classification_report(y_test, predtest_y, target_names=target_names))\n",
    "\n",
    "confusion = confusion_matrix(y_test, predtest_y)\n",
    "print(confusion)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_test = pd.crosstab(y_test, predtest_y, margins=True)\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0] / table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0] / table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Logistics accuracy: {}\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    ").format(cross_val_score(lr,X_testvec,y_test,cv=kf).mean(),test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TFIDF***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "vect2 = TfidfVectorizer(min_df=20, analyzer = 'word', stop_words = 'english',\n",
    "                        ngram_range = (1,3)\n",
    "                       ).fit(X_train)\n",
    "\n",
    "X_train_vectorized = vect2.transform(X_train)\n",
    "X_test_vectorized = vect2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12146\n"
     ]
    }
   ],
   "source": [
    "features_names = vect2.get_feature_names()\n",
    "print(len(features_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Logistic Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'penalty': 'l2', 'C': 2, 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "\n",
    "lr2 = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "#Create range of values to fit parameters\n",
    "\n",
    "k1 = ['l1', 'l2']\n",
    "k2 = np.arange(50) + 1\n",
    "k3 = ['balanced', None]\n",
    "\n",
    "parameters = {'penalty': k1,\n",
    "          'C': k2,\n",
    "          'class_weight':k3}\n",
    "\n",
    "#Fit parameters\n",
    "\n",
    "lrr = GridSearchCV(lr2, param_grid=parameters, cv=kf)\n",
    "\n",
    "#Fit on Training set\n",
    "lrr.fit(X_train_vectorized, y_train)\n",
    "\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\", lrr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Once the model has been trained test it on the test dataset\n",
    "lr2.fit(X_test_vectorized, y_test)\n",
    "\n",
    "# Predict on test set\n",
    "predtest2_y = lrr.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.81      0.81      3778\n",
      "        1.0       0.81      0.81      0.81      3776\n",
      "\n",
      "avg / total       0.81      0.81      0.81      7554\n",
      "\n",
      "[[3048  730]\n",
      " [ 712 3064]]\n",
      "Losgistics model accuracy: 0.7814397727920197\n",
      "Percent Type I errors: 0.09663754302356367\n",
      "Percent Type II errors: 0.09425469949695525\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate model (test set)\n",
    "target_names = ['0.0', '1.0']\n",
    "print(classification_report(y_test, predtest2_y, target_names=target_names))\n",
    "\n",
    "confusion = confusion_matrix(y_test, predtest2_y)\n",
    "print(confusion)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_test = pd.crosstab(y_test, predtest2_y, margins=True)\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0] / table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0] / table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Losgistics model accuracy: {}\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    ").format(cross_val_score(lr2,X_test_vectorized,y_test,cv=kf).mean(),test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Bernouilli Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'alpha': 1}\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "\n",
    "l3 = BernoulliNB()\n",
    "\n",
    "#Create range of values to fit parameters\n",
    "\n",
    "\n",
    "k1 = np.arange(50) + 1\n",
    "\n",
    "\n",
    "parameters = {'alpha': k1\n",
    "          }\n",
    "\n",
    "#Fit parameters\n",
    "\n",
    "l33 = GridSearchCV(l3, param_grid=parameters, cv=kf)\n",
    "\n",
    "#Fit on Training set\n",
    "l33.fit(X_train_vectorized, y_train)\n",
    "\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\", l33.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict on the test data set\n",
    "\n",
    "l33.fit(X_test_vectorized, y_test)\n",
    "\n",
    "# Predict on training set\n",
    "predtest3_y = l33.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.76      0.88      0.82      3778\n",
      "        1.0       0.86      0.72      0.78      3776\n",
      "\n",
      "avg / total       0.81      0.80      0.80      7554\n",
      "\n",
      "[[3325  453]\n",
      " [1052 2724]]\n",
      "Bernouilli set accuracy: 0.720148842264892\n",
      "Percent Type I errors: 0.05996822875297855\n",
      "Percent Type II errors: 0.13926396611066985\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of the model (testing)\n",
    "\n",
    "target_names = ['0.0', '1.0']\n",
    "print(classification_report(y_test, predtest3_y, target_names=target_names))\n",
    "\n",
    "confusion = confusion_matrix(y_test, predtest3_y)\n",
    "print(confusion)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_test = pd.crosstab(y_test, predtest3_y, margins=True)\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0] / table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0] / table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Bernouilli set accuracy: {}\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    ").format(cross_val_score(l33,X_test_vectorized,y_test,cv=kf).mean(),test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***KNN model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'weights': 'distance', 'n_neighbors': 19}\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model\n",
    "KNN = KNeighborsClassifier(n_jobs=-1)\n",
    "\n",
    "#Create range of values to fit parameters\n",
    "\n",
    "k1 = [1,3,5,7,9,11,13,15,17,19,21]\n",
    "k3 = ['uniform', 'distance']\n",
    "\n",
    "parameters = {'n_neighbors': k1,\n",
    "          'weights':k3}\n",
    "\n",
    "#Fit parameters\n",
    "\n",
    "clf = GridSearchCV(KNN, param_grid=parameters, cv=kf)\n",
    "\n",
    "#Fit the tunned model\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize the model on test dataset\n",
    "\n",
    "clf.fit(X_test_vectorized, y_test)\n",
    "\n",
    "# Predict on test dataset\n",
    "\n",
    "predtest3_y = clf.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.72      0.66      0.69      3778\n",
      "        1.0       0.69      0.74      0.71      3776\n",
      "\n",
      "avg / total       0.70      0.70      0.70      7554\n",
      "\n",
      "[[2503 1275]\n",
      " [ 982 2794]]\n",
      "KNN accuracy: 0.6486637944258661\n",
      "Percent Type I errors: 0.1687847498014297\n",
      "Percent Type II errors: 0.12999735239608154\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate model on the test set\n",
    "target_names = ['0.0', '1.0']\n",
    "print(classification_report(y_test, predtest3_y, target_names=target_names))\n",
    "\n",
    "#Create confusion matrix\n",
    "confusion = confusion_matrix(y_test, predtest3_y)\n",
    "print(confusion)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_test = pd.crosstab(y_test, predtest3_y, margins=True)\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0] / table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0] / table_test.loc['All','All']\n",
    "\n",
    "#Print Results\n",
    "print((\n",
    "    'KNN accuracy: {}\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    ").format(cross_val_score(clf,X_test_vectorized,y_test,cv=kf).mean(),test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Random Forest***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/borjaregueral/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.86391, std: 0.00701, params: {'n_estimators': 300},\n",
       "  mean: 0.86315, std: 0.00787, params: {'n_estimators': 320},\n",
       "  mean: 0.86284, std: 0.00716, params: {'n_estimators': 340},\n",
       "  mean: 0.86417, std: 0.00734, params: {'n_estimators': 360},\n",
       "  mean: 0.86349, std: 0.00742, params: {'n_estimators': 380}],\n",
       " {'n_estimators': 360},\n",
       " 0.86417204831138184)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For the Random Forest hyperparameters tuning,due to computational restrictions,\n",
    "#grid search will be applied to one paramter at a time on the train set\n",
    "#updating the value as we move along the hyperparameters tuning\n",
    "\n",
    "#Number of trees\n",
    "\n",
    "param_test1 = {'n_estimators':range(300,400,20)}\n",
    "gsearch1 = GridSearchCV(estimator = RandomForestClassifier(), \n",
    "param_grid = param_test1, scoring='roc_auc',n_jobs=-1,iid=False, cv=kf)\n",
    "gsearch1.fit(X_train_vectorized, y_train)\n",
    "\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/borjaregueral/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.86376, std: 0.00659, params: {'max_depth': 61, 'min_samples_split': 80},\n",
       "  mean: 0.86345, std: 0.00682, params: {'max_depth': 61, 'min_samples_split': 100},\n",
       "  mean: 0.86376, std: 0.00707, params: {'max_depth': 61, 'min_samples_split': 120},\n",
       "  mean: 0.86442, std: 0.00665, params: {'max_depth': 63, 'min_samples_split': 80},\n",
       "  mean: 0.86414, std: 0.00645, params: {'max_depth': 63, 'min_samples_split': 100},\n",
       "  mean: 0.86419, std: 0.00699, params: {'max_depth': 63, 'min_samples_split': 120},\n",
       "  mean: 0.86485, std: 0.00728, params: {'max_depth': 65, 'min_samples_split': 80},\n",
       "  mean: 0.86465, std: 0.00625, params: {'max_depth': 65, 'min_samples_split': 100},\n",
       "  mean: 0.86395, std: 0.00729, params: {'max_depth': 65, 'min_samples_split': 120},\n",
       "  mean: 0.86346, std: 0.00706, params: {'max_depth': 67, 'min_samples_split': 80},\n",
       "  mean: 0.86335, std: 0.00671, params: {'max_depth': 67, 'min_samples_split': 100},\n",
       "  mean: 0.86352, std: 0.00703, params: {'max_depth': 67, 'min_samples_split': 120},\n",
       "  mean: 0.86423, std: 0.00675, params: {'max_depth': 69, 'min_samples_split': 80},\n",
       "  mean: 0.86455, std: 0.00710, params: {'max_depth': 69, 'min_samples_split': 100},\n",
       "  mean: 0.86444, std: 0.00736, params: {'max_depth': 69, 'min_samples_split': 120},\n",
       "  mean: 0.86403, std: 0.00690, params: {'max_depth': 71, 'min_samples_split': 80},\n",
       "  mean: 0.86329, std: 0.00753, params: {'max_depth': 71, 'min_samples_split': 100},\n",
       "  mean: 0.86358, std: 0.00720, params: {'max_depth': 71, 'min_samples_split': 120},\n",
       "  mean: 0.86344, std: 0.00654, params: {'max_depth': 73, 'min_samples_split': 80},\n",
       "  mean: 0.86314, std: 0.00651, params: {'max_depth': 73, 'min_samples_split': 100},\n",
       "  mean: 0.86337, std: 0.00703, params: {'max_depth': 73, 'min_samples_split': 120},\n",
       "  mean: 0.86410, std: 0.00693, params: {'max_depth': 75, 'min_samples_split': 80},\n",
       "  mean: 0.86388, std: 0.00681, params: {'max_depth': 75, 'min_samples_split': 100},\n",
       "  mean: 0.86461, std: 0.00747, params: {'max_depth': 75, 'min_samples_split': 120},\n",
       "  mean: 0.86407, std: 0.00717, params: {'max_depth': 77, 'min_samples_split': 80},\n",
       "  mean: 0.86399, std: 0.00632, params: {'max_depth': 77, 'min_samples_split': 100},\n",
       "  mean: 0.86398, std: 0.00675, params: {'max_depth': 77, 'min_samples_split': 120},\n",
       "  mean: 0.86373, std: 0.00704, params: {'max_depth': 79, 'min_samples_split': 80},\n",
       "  mean: 0.86456, std: 0.00765, params: {'max_depth': 79, 'min_samples_split': 100},\n",
       "  mean: 0.86269, std: 0.00710, params: {'max_depth': 79, 'min_samples_split': 120}],\n",
       " {'max_depth': 65, 'min_samples_split': 80},\n",
       " 0.86485199295623083)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Max depth and min sample split\n",
    "#Tried values for max depth from 2-60 with values under 0.8641. To find the value that increases accuracy\n",
    "# the range between 60-80 is used\n",
    "# min sample split values from 50-500 being the value between 80-120 the ones that increases accuracy\n",
    "\n",
    "param_test2 = {'max_depth':range(61,80,2), 'min_samples_split': range(80,121,20)}\n",
    "gsearch2 = GridSearchCV(estimator =  RandomForestClassifier(n_estimators = 360), \n",
    "param_grid = param_test2, scoring='roc_auc',n_jobs=-1,iid=False, cv=kf)\n",
    "gsearch2.fit(X_train_vectorized, y_train)\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/borjaregueral/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.86420, std: 0.00733, params: {'min_samples_leaf': 2},\n",
       "  mean: 0.86124, std: 0.00704, params: {'min_samples_leaf': 12},\n",
       "  mean: 0.85649, std: 0.00648, params: {'min_samples_leaf': 22},\n",
       "  mean: 0.85188, std: 0.00774, params: {'min_samples_leaf': 32}],\n",
       " {'min_samples_leaf': 2},\n",
       " 0.86419681801895831)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Re run the min_sample split with the min_sample leaf\n",
    "\n",
    "param_test3 = {'min_samples_leaf':range(2,33,10)}\n",
    "gsearch3 = GridSearchCV(estimator = RandomForestClassifier(n_estimators = 360, max_depth = 65 , min_samples_split = 80 ), \n",
    "param_grid = param_test3, scoring='roc_auc',n_jobs=-1,iid=False, cv=kf)\n",
    "gsearch3.fit(X_train_vectorized, y_train)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/borjaregueral/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.86409, std: 0.00655, params: {'criterion': 'gini'},\n",
       "  mean: 0.86604, std: 0.00717, params: {'criterion': 'entropy'}],\n",
       " {'criterion': 'entropy'},\n",
       " 0.8660437108853406)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Based on the results shown for the minimum sample split, we will lwave it in the default number\n",
    "#Re run the min_sample split with the min_sample leaf\n",
    "\n",
    "param_test4 = {'criterion':['gini', 'entropy']}\n",
    "gsearch4 = GridSearchCV(estimator = RandomForestClassifier(n_estimators = 360, max_depth = 65 , min_samples_split = 80), \n",
    "param_grid = param_test4, scoring='roc_auc',n_jobs=-1,iid=False, cv=kf)\n",
    "gsearch4.fit(X_train_vectorized, y_train)\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit in test dataset\n",
    "gsearch4.fit(X_test_vectorized, y_test)\n",
    "\n",
    "#Predict on test dataset\n",
    "predtestrf_y = gsearch4.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96      3778\n",
      "          1       0.96      0.96      0.96      3776\n",
      "\n",
      "avg / total       0.96      0.96      0.96      7554\n",
      "\n",
      "[[3613  165]\n",
      " [ 160 3616]]\n",
      "Random Forest accuracy:0.8555924187636264\n",
      "Percent Type I errors: 0.021842732327243843\n",
      "Percent Type II errors: 0.021180831347630394\n"
     ]
    }
   ],
   "source": [
    "#Test Scores\n",
    "target_names = ['0', '1']\n",
    "print(classification_report(y_test, predtestrf_y, target_names=target_names))\n",
    "cnf = confusion_matrix(y_test, predtestrf_y)\n",
    "print(cnf)\n",
    "\n",
    "table_test = pd.crosstab(y_test, predtestrf_y, margins=True)\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Random Forest accuracy:{}\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(cross_val_score(gsearch4,X_test_vectorized,y_test,cv=kf).mean(),test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Decision Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'max_features': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "OTM = DecisionTreeClassifier()\n",
    "\n",
    "#Create range of values to fit parameters\n",
    "\n",
    "\n",
    "k2 = ['auto', 'sqrt', 'log2']\n",
    "\n",
    "\n",
    "parameters = {'max_features': k2\n",
    "         }\n",
    "\n",
    "#Fit parameters\n",
    "\n",
    "OTM1 = GridSearchCV(OTM, param_grid=parameters, cv=kf)\n",
    "\n",
    "#Fit the tunned model\n",
    "OTM1.fit(X_train_vectorized, y_train)\n",
    "\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\", OTM1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit on test dataset\n",
    "OTM1.fit(X_test_vectorized, y_test)\n",
    "\n",
    "#Predict parameters on test dataset\n",
    "\n",
    "predtestrf_y = OTM1.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3778\n",
      "          1       1.00      1.00      1.00      3776\n",
      "\n",
      "avg / total       1.00      1.00      1.00      7554\n",
      "\n",
      "[[3778    0]\n",
      " [   0 3776]]\n",
      "Decision Tree accuracy:0.6329100065304762\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Test Scores\n",
    "target_names = ['0', '1']\n",
    "print(classification_report(y_test, predtestrf_y, target_names=target_names))\n",
    "cnf = confusion_matrix(y_test, predtestrf_y)\n",
    "print(cnf)\n",
    "\n",
    "table_test = pd.crosstab(y_test, predtestrf_y, margins=True)\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Decision Tree accuracy:{}\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(cross_val_score(OTM1,X_test_vectorized,y_test,cv=kf).mean(),test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SVC***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'C': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "svc = SVC()\n",
    "\n",
    "#Create range of values to fit parameters\n",
    "ks1 = np.arange(20)+1\n",
    "ks4 =  ['linear','rbf']\n",
    "\n",
    "\n",
    "parameters = {'C': ks1, \n",
    "          'kernel': ks4}\n",
    "\n",
    "#Fit parameters\n",
    "\n",
    "svc1 = GridSearchCV(svc, param_grid=parameters, cv=kf)\n",
    "\n",
    "#Fit the tunned model\n",
    "svc1.fit(X_train_vectorized, y_train)\n",
    "\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\", svc1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit tunned model on Test set\n",
    "svc1.fit(X_test_vectorized, y_test)\n",
    "\n",
    "# Predict on training set\n",
    "predtestsvc_y = svc1.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.93      0.93      3778\n",
      "        1.0       0.93      0.93      0.93      3776\n",
      "\n",
      "avg / total       0.93      0.93      0.93      7554\n",
      "\n",
      "[[3505  273]\n",
      " [ 258 3518]]\n",
      "SVC accuracy:0.7724370948584551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test Scores\n",
    "target_names = ['0.0', '1.0']\n",
    "print(classification_report(y_test, predtestsvc_y, target_names=target_names))\n",
    "cnf = confusion_matrix(y_test, predtestsvc_y)\n",
    "print(cnf)\n",
    "\n",
    "table_test = pd.crosstab(y_test, predtestsvc_y, margins=True)\n",
    "\n",
    "\n",
    "print((\n",
    "    'SVC accuracy:{}\\n'\n",
    ").format(cross_val_score(svc1,X_test_vectorized,y_test,cv=kf).mean(),test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Gradient Boosting***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Borja.gonzalez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.80878, std: 0.00767, params: {'n_estimators': 20},\n",
       "  mean: 0.82311, std: 0.00697, params: {'n_estimators': 30},\n",
       "  mean: 0.83342, std: 0.00619, params: {'n_estimators': 40},\n",
       "  mean: 0.84029, std: 0.00678, params: {'n_estimators': 50},\n",
       "  mean: 0.84511, std: 0.00659, params: {'n_estimators': 60},\n",
       "  mean: 0.84968, std: 0.00764, params: {'n_estimators': 70},\n",
       "  mean: 0.85292, std: 0.00728, params: {'n_estimators': 80}],\n",
       " {'n_estimators': 80},\n",
       " 0.85291738509922832)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For the Gradient Boosting hyperparameters tuning,due to computational restrictions,\n",
    "#grid search will be applied to one paramter at a time on the train set\n",
    "#updating the value as we move along the hyperparameters tuning\n",
    "\n",
    "#Number of trees\n",
    "\n",
    "param_test1 = {'n_estimators':range(20,90,10)}\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, min_samples_split=500,min_samples_leaf=50,max_depth=8,max_features='sqrt',subsample=0.8,random_state=10), \n",
    "param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=kf)\n",
    "gsearch1.fit(X_train_vectorized, y_train)\n",
    "\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Borja.gonzalez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.83937, std: 0.00461, params: {'min_samples_split': 200, 'max_depth': 5},\n",
       "  mean: 0.84016, std: 0.00663, params: {'min_samples_split': 400, 'max_depth': 5},\n",
       "  mean: 0.83995, std: 0.00701, params: {'min_samples_split': 600, 'max_depth': 5},\n",
       "  mean: 0.84096, std: 0.00706, params: {'min_samples_split': 800, 'max_depth': 5},\n",
       "  mean: 0.84100, std: 0.00685, params: {'min_samples_split': 1000, 'max_depth': 5},\n",
       "  mean: 0.84833, std: 0.00531, params: {'min_samples_split': 200, 'max_depth': 7},\n",
       "  mean: 0.85060, std: 0.00684, params: {'min_samples_split': 400, 'max_depth': 7},\n",
       "  mean: 0.85056, std: 0.00752, params: {'min_samples_split': 600, 'max_depth': 7},\n",
       "  mean: 0.85023, std: 0.00731, params: {'min_samples_split': 800, 'max_depth': 7},\n",
       "  mean: 0.84960, std: 0.00763, params: {'min_samples_split': 1000, 'max_depth': 7},\n",
       "  mean: 0.85455, std: 0.00780, params: {'min_samples_split': 200, 'max_depth': 9},\n",
       "  mean: 0.85437, std: 0.00777, params: {'min_samples_split': 400, 'max_depth': 9},\n",
       "  mean: 0.85509, std: 0.00643, params: {'min_samples_split': 600, 'max_depth': 9},\n",
       "  mean: 0.85504, std: 0.00679, params: {'min_samples_split': 800, 'max_depth': 9},\n",
       "  mean: 0.85535, std: 0.00688, params: {'min_samples_split': 1000, 'max_depth': 9},\n",
       "  mean: 0.85949, std: 0.00584, params: {'min_samples_split': 200, 'max_depth': 11},\n",
       "  mean: 0.85920, std: 0.00534, params: {'min_samples_split': 400, 'max_depth': 11},\n",
       "  mean: 0.86057, std: 0.00700, params: {'min_samples_split': 600, 'max_depth': 11},\n",
       "  mean: 0.86026, std: 0.00740, params: {'min_samples_split': 800, 'max_depth': 11},\n",
       "  mean: 0.85975, std: 0.00743, params: {'min_samples_split': 1000, 'max_depth': 11},\n",
       "  mean: 0.86150, std: 0.00955, params: {'min_samples_split': 200, 'max_depth': 13},\n",
       "  mean: 0.86202, std: 0.00714, params: {'min_samples_split': 400, 'max_depth': 13},\n",
       "  mean: 0.86259, std: 0.00879, params: {'min_samples_split': 600, 'max_depth': 13},\n",
       "  mean: 0.86326, std: 0.00772, params: {'min_samples_split': 800, 'max_depth': 13},\n",
       "  mean: 0.86315, std: 0.00806, params: {'min_samples_split': 1000, 'max_depth': 13},\n",
       "  mean: 0.86425, std: 0.00702, params: {'min_samples_split': 200, 'max_depth': 15},\n",
       "  mean: 0.86433, std: 0.00792, params: {'min_samples_split': 400, 'max_depth': 15},\n",
       "  mean: 0.86482, std: 0.00760, params: {'min_samples_split': 600, 'max_depth': 15},\n",
       "  mean: 0.86464, std: 0.00753, params: {'min_samples_split': 800, 'max_depth': 15},\n",
       "  mean: 0.86411, std: 0.00764, params: {'min_samples_split': 1000, 'max_depth': 15},\n",
       "  mean: 0.86398, std: 0.00732, params: {'min_samples_split': 200, 'max_depth': 17},\n",
       "  mean: 0.86521, std: 0.00788, params: {'min_samples_split': 400, 'max_depth': 17},\n",
       "  mean: 0.86633, std: 0.00740, params: {'min_samples_split': 600, 'max_depth': 17},\n",
       "  mean: 0.86566, std: 0.00733, params: {'min_samples_split': 800, 'max_depth': 17},\n",
       "  mean: 0.86570, std: 0.00815, params: {'min_samples_split': 1000, 'max_depth': 17},\n",
       "  mean: 0.86493, std: 0.00716, params: {'min_samples_split': 200, 'max_depth': 19},\n",
       "  mean: 0.86619, std: 0.00929, params: {'min_samples_split': 400, 'max_depth': 19},\n",
       "  mean: 0.86735, std: 0.00845, params: {'min_samples_split': 600, 'max_depth': 19},\n",
       "  mean: 0.86614, std: 0.00993, params: {'min_samples_split': 800, 'max_depth': 19},\n",
       "  mean: 0.86669, std: 0.00809, params: {'min_samples_split': 1000, 'max_depth': 19}],\n",
       " {'max_depth': 19, 'min_samples_split': 600},\n",
       " 0.86734849040457307)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Max depth and min sample split\n",
    "\n",
    "param_test2 = {'max_depth':range(5,20,2), 'min_samples_split':range(200,1001,200)}\n",
    "gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=80, max_features='sqrt', subsample=0.8, random_state=10), \n",
    "param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=kf)\n",
    "gsearch2.fit(X_train_vectorized, y_train)\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Borja.gonzalez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.86820, std: 0.00800, params: {'min_samples_leaf': 30, 'min_samples_split': 200},\n",
       "  mean: 0.86801, std: 0.00826, params: {'min_samples_leaf': 30, 'min_samples_split': 400},\n",
       "  mean: 0.86783, std: 0.00753, params: {'min_samples_leaf': 30, 'min_samples_split': 600},\n",
       "  mean: 0.86806, std: 0.00847, params: {'min_samples_leaf': 30, 'min_samples_split': 800},\n",
       "  mean: 0.86849, std: 0.00782, params: {'min_samples_leaf': 30, 'min_samples_split': 1000},\n",
       "  mean: 0.86738, std: 0.00886, params: {'min_samples_leaf': 40, 'min_samples_split': 200},\n",
       "  mean: 0.86735, std: 0.00880, params: {'min_samples_leaf': 40, 'min_samples_split': 400},\n",
       "  mean: 0.86721, std: 0.00915, params: {'min_samples_leaf': 40, 'min_samples_split': 600},\n",
       "  mean: 0.86865, std: 0.00908, params: {'min_samples_leaf': 40, 'min_samples_split': 800},\n",
       "  mean: 0.86869, std: 0.00832, params: {'min_samples_leaf': 40, 'min_samples_split': 1000},\n",
       "  mean: 0.86677, std: 0.00887, params: {'min_samples_leaf': 50, 'min_samples_split': 200},\n",
       "  mean: 0.86669, std: 0.00907, params: {'min_samples_leaf': 50, 'min_samples_split': 400},\n",
       "  mean: 0.86659, std: 0.00791, params: {'min_samples_leaf': 50, 'min_samples_split': 600},\n",
       "  mean: 0.86727, std: 0.00763, params: {'min_samples_leaf': 50, 'min_samples_split': 800},\n",
       "  mean: 0.86718, std: 0.00766, params: {'min_samples_leaf': 50, 'min_samples_split': 1000},\n",
       "  mean: 0.86577, std: 0.00748, params: {'min_samples_leaf': 60, 'min_samples_split': 200},\n",
       "  mean: 0.86595, std: 0.00901, params: {'min_samples_leaf': 60, 'min_samples_split': 400},\n",
       "  mean: 0.86572, std: 0.00821, params: {'min_samples_leaf': 60, 'min_samples_split': 600},\n",
       "  mean: 0.86594, std: 0.00813, params: {'min_samples_leaf': 60, 'min_samples_split': 800},\n",
       "  mean: 0.86624, std: 0.00863, params: {'min_samples_leaf': 60, 'min_samples_split': 1000},\n",
       "  mean: 0.86534, std: 0.00838, params: {'min_samples_leaf': 70, 'min_samples_split': 200},\n",
       "  mean: 0.86509, std: 0.00839, params: {'min_samples_leaf': 70, 'min_samples_split': 400},\n",
       "  mean: 0.86408, std: 0.00842, params: {'min_samples_leaf': 70, 'min_samples_split': 600},\n",
       "  mean: 0.86564, std: 0.00778, params: {'min_samples_leaf': 70, 'min_samples_split': 800},\n",
       "  mean: 0.86477, std: 0.00791, params: {'min_samples_leaf': 70, 'min_samples_split': 1000}],\n",
       " {'min_samples_leaf': 40, 'min_samples_split': 1000},\n",
       " 0.86868667888309969)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Re run the min_sample split with the min_sample leaf\n",
    "\n",
    "param_test3 = {'min_samples_split':range(200,1001,200),'min_samples_leaf':range(30,71,10)}\n",
    "gsearch3 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=80,max_depth=19,min_samples_split=600,max_features='sqrt', subsample=0.8, random_state=10), \n",
    "param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=kf)\n",
    "gsearch3.fit(X_train_vectorized, y_train)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Borja.gonzalez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.86701, std: 0.00804, params: {'max_features': 60},\n",
       "  mean: 0.86901, std: 0.00760, params: {'max_features': 62},\n",
       "  mean: 0.86734, std: 0.00602, params: {'max_features': 64},\n",
       "  mean: 0.86519, std: 0.00793, params: {'max_features': 66},\n",
       "  mean: 0.86706, std: 0.00683, params: {'max_features': 68},\n",
       "  mean: 0.86695, std: 0.00803, params: {'max_features': 70},\n",
       "  mean: 0.86729, std: 0.00684, params: {'max_features': 72}],\n",
       " {'max_features': 62},\n",
       " 0.86900925427507347)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Max features considering the results obtained\n",
    "#for the combination of the 'min_samples_split', 'min_samples_leaf' and 'max_depth'\n",
    "#The value of 600 has been maintained as it is the one that gives a better accuracy for every value of 'max_depth'\n",
    "\n",
    "param_test4 = {'max_features':range(60,74,2)}\n",
    "gsearch4 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=80,max_depth=19,min_samples_split=600,min_samples_leaf=40,max_features='sqrt', subsample=0.8, random_state=10),\n",
    "param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=kf)\n",
    "gsearch4.fit(X_train_vectorized, y_train)\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Borja.gonzalez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.86620, std: 0.00542, params: {'subsample': 0.6},\n",
       "  mean: 0.86623, std: 0.00720, params: {'subsample': 0.7},\n",
       "  mean: 0.86797, std: 0.00603, params: {'subsample': 0.75},\n",
       "  mean: 0.86909, std: 0.00640, params: {'subsample': 0.8},\n",
       "  mean: 0.86897, std: 0.00591, params: {'subsample': 0.85},\n",
       "  mean: 0.86923, std: 0.00523, params: {'subsample': 0.9},\n",
       "  mean: 0.86812, std: 0.00616, params: {'subsample': 0.95}],\n",
       " {'subsample': 0.9},\n",
       " 0.86922953360660782)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tuning the subsample \n",
    "param_test5 = {'subsample':[0.6,0.7,0.75,0.8,0.85,0.9,0.95]}\n",
    "gsearch5 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1,\n",
    "                                                               n_estimators=80,max_depth=19,min_samples_split=600,\n",
    "                                                               min_samples_leaf=40,max_features=62,\n",
    "                                                               subsample=0.8, random_state=10),\n",
    "param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=kf)\n",
    "gsearch5.fit(X_train_vectorized, y_train)\n",
    "gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Borja.gonzalez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.87311, std: 0.00652, params: {'subsample': 0.8},\n",
       "  mean: 0.87419, std: 0.00581, params: {'subsample': 0.85},\n",
       "  mean: 0.87360, std: 0.00622, params: {'subsample': 0.9},\n",
       "  mean: 0.87388, std: 0.00629, params: {'subsample': 0.95}],\n",
       " {'subsample': 0.85},\n",
       " 0.87418850927374303)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instead of having a 10% learning rate, we halve the learning rate and double the number of trees to see if we\n",
    "#can improve the accuracy\n",
    "\n",
    "param_test5 = {'subsample':[0.8,0.85,0.9,0.95]}\n",
    "gsearch5 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.05, n_estimators=160,\n",
    "                                                               max_depth=19,min_samples_split=600,\n",
    "                                                               min_samples_leaf=40,max_features=62,\n",
    "                                                               subsample=0.9, random_state=10),\n",
    "param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=kf)\n",
    "gsearch5.fit(X_train_vectorized, y_train)\n",
    "gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit on the test set\n",
    "gsearch5.fit(X_test_vectorized, y_test)\n",
    "\n",
    "# Predict on test set\n",
    "predtestrf_y = gsearch5.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.84      0.85      3778\n",
      "          1       0.85      0.87      0.86      3776\n",
      "\n",
      "avg / total       0.86      0.86      0.86      7554\n",
      "\n",
      "[[3179  599]\n",
      " [ 496 3280]]\n",
      "Gradient Boosting accuracy:0.859686734099706\n",
      "Percent Type I errors: 0.07929573735769128\n",
      "Percent Type II errors: 0.06566057717765422\n"
     ]
    }
   ],
   "source": [
    "#Test Scores\n",
    "target_names = ['0', '1']\n",
    "print(classification_report(y_test, predtestrf_y, target_names=target_names))\n",
    "cnf = confusion_matrix(y_test, predtestrf_y)\n",
    "print(cnf)\n",
    "\n",
    "table_test = pd.crosstab(y_test, predtestrf_y, margins=True)\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Gradient Boosting accuracy:{}\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(cross_val_score(gsearch5,X_test_vectorized,y_test,cv=kf).mean(),test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the amazon reviews analysis the digital music dataset has been used. To create both categories, ratings 1-3 have been included as negative and 4-5 as positive. This has been done because in the raw data, ratings are skewed to the positive side being the average around 4.0. Data once categorized has been downsampled to reduce the biased towards the positive reviews of the models that have been run.\n",
    "\n",
    "To build up the features the bag of words and the TFIDF have been used. In both cases, stop words in English have been extracted so that the number of features is reduced. From the bag of words, 59374 features were built. Additionally, only those that appear in more than 20 reviews have been used. In this case, the Nave-Bayes and the logistic Regression models wwere used. The accuracy in each case was of 0.6943 and 0.7495.\n",
    "\n",
    "The TFIDF was applied considering n-grams (1,3) and the number of features was reduced to 11926. The initial models (Nave-Bayes and Logistic Regression) were tested on the features extracted with the TFIDF to see if there was a significant improvement in the accuracy. The accuracies in both cases were Niave Bayes: 0.7201 and Logistic Regression: 0.7814 that were considered as the starting points for the use of the TFIDF features.\n",
    "\n",
    "In all cases, models were tuned in the training sets using gridsearch and the accuracy results obtained are (excluding Logistic Regression and Nave Bayes classifiers already mentioned):\n",
    "\n",
    "Decision Tree: 0.6329\n",
    "KNN: 0.6486\n",
    "Random Forest: 0.8556\n",
    "SVC: 0.7724\n",
    "Gradient Boosting: 0.8597"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
